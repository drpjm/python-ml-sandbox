{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Concepts and API\n",
    "\n",
    "All TF code follows this process:\n",
    "1. Create a **computation graph** that defines your computational structure\n",
    "2. Create a TF session\n",
    "3. Run the computation graph in the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Define variables and operations in the graph\n",
    "\n",
    "x = tf.Variable(3, name=\"x\") # declare a symbolic name, x\n",
    "y = tf.Variable(4, name=\"y\")\n",
    "g = x*x*y\n",
    "h = y**3\n",
    "print(type(g))\n",
    "print(type(h))\n",
    "f = g + h\n",
    "print(type(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *type* of each computation is a TF **op**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a session and run. Using the \"with\" context block automatically closes the session.\n",
    "with tf.Session() as tf_sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = f.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative to initializing variables individually is to call the <code>global_variables_initializer</code> function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer() # Creates an init node\n",
    "\n",
    "with tf.Session() as tf_sess:\n",
    "    init.run()\n",
    "    result = f.eval()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphs\n",
    "\n",
    "We can build graphs and then merge them together programmatically. Otherwise, it is assumed that declared computations are applied to the **same graph**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = tf.Variable(1)\n",
    "# check where this x1 node lives:\n",
    "x1.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Now, make another graph and add a new variable to it:\n",
    "new_graph = tf.Graph()\n",
    "with new_graph.as_default():\n",
    "    x2 = tf.Variable(2)\n",
    "    \n",
    "print(x2.graph is tf.get_default_graph())\n",
    "print(x2.graph is new_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More on Nodes\n",
    "\n",
    "TF node evaluation determines the set of nodes that the node depends on and evaluates them. **All node values (except variables) are dropped between graph runs!**\n",
    "\n",
    "Varialbes start their life when initialized and end when the session closes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "3969\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "w = tf.constant(9)\n",
    "x = w * 7\n",
    "y = x + 2\n",
    "z = x**2\n",
    "\n",
    "with tf.Session() as tf_sess:\n",
    "    print(y.eval())\n",
    "    print(z.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code is not efficient, as the computation of x and w will happen twice! Instead, have y and evaluate in a single graph run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "3969\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as tf_sess:\n",
    "    y_val, z_val = tf_sess.run([y,z])\n",
    "    print(y_val)\n",
    "    print(z_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations\n",
    "\n",
    "TF \"ops\" can take *any* number of inputs and produce *any* number of outputs. Sources are constants and Variables. The inputs and outputs of operations are always **tensors** - multi-dimensional arrays. In TF, tensors are numpy <code>ndarray</code>s.\n",
    "\n",
    "The following example performs linear regression using the closed form Normal Equation embedded as a TF op."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: 20640 instances, 8 features\n",
      "Training size: 16512; Test size: 4128\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "housing_dataset = fetch_california_housing()\n",
    "m,n = housing_dataset.data.shape\n",
    "print(\"Data shape: \" + str(m) + \" instances, \" + str(n) + \" features\")\n",
    "\n",
    "X_raw = housing_dataset.data\n",
    "y_raw = housing_dataset.target\n",
    "\n",
    "# Split up the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_raw, y_raw, test_size=0.2)\n",
    "print(\"Training size: \" + str(X_train.shape[0]) + \"; Test size: \" + str(X_test.shape[0]))\n",
    "\n",
    "# Scale the data sets\n",
    "housing_scaler = StandardScaler()\n",
    "X_train_scaled = housing_scaler.fit_transform(X_train)\n",
    "X_test_scaled = housing_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biased train data shape: 16512 instances, 9 features\n",
      "Biased test data shape: 4128 instances, 9 features\n"
     ]
    }
   ],
   "source": [
    "# Add a bias of 1 to model the linear regression.\n",
    "X_train_biased = np.c_[np.ones((X_train_scaled.shape[0],1)), X_train_scaled]\n",
    "X_test_biased = np.c_[np.ones((X_test_scaled.shape[0],1)), X_test_scaled]\n",
    "print(\"Biased train data shape: \" + str(X_train_biased.shape[0]) + \" instances, \" + str(X_train_biased.shape[1]) + \" features\")\n",
    "print(\"Biased test data shape: \" + str(X_test_biased.shape[0]) + \" instances, \" + str(X_test_biased.shape[1]) + \" features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target array shape: (16512, 9)\n",
      "...as TF constant: (16512,)\n"
     ]
    }
   ],
   "source": [
    "X = tf.constant(X_train_biased, dtype=tf.float32, name=\"X\")\n",
    "print(\"Target array shape: \" + str(X_train_biased.shape))\n",
    "# Explicitly turn into an m x 1 vector\n",
    "y = tf.constant(y_train.reshape(-1,1), dtype=tf.float32, name=\"y\")\n",
    "print(\"...as TF constant: \" + str(y_train.shape))\n",
    "XT = tf.transpose(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the Normal Equation:\n",
    "$\\theta^{\\star} = (X\\cdot X^T)^{-1}\\cdot{X^T}\\cdot{y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv = tf.matrix_inverse( tf.matmul(XT, X) )\n",
    "theta = tf.matmul( tf.matmul(inv, XT), y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vroom vroom!\n",
    "with tf.Session() as tf_sess:\n",
    "    theta_val = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performed a linear regression over the data set:\n",
      "[[ 2.0638726 ]\n",
      " [ 0.8261018 ]\n",
      " [ 0.11529301]\n",
      " [-0.25263292]\n",
      " [ 0.2780502 ]\n",
      " [-0.00636555]\n",
      " [-0.02895787]\n",
      " [-0.8981792 ]\n",
      " [-0.87140805]]\n",
      " (9, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Performed a linear regression over the data set:\")\n",
    "print(str(theta_val) + \"\\n \" + str(theta_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Gradient Descent via TF\n",
    "\n",
    "I will re-use the scaled data from above and implement gradient descent manually rather than use the normal equation solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For grins, make a new graph for this implementation.\n",
    "gd_graph = tf.Graph()\n",
    "m = X_train_biased.shape[0]\n",
    "n = X_train_biased.shape[1]\n",
    "\n",
    "n_epochs = 2000\n",
    "alpha = 0.01 # learning rate\n",
    "\n",
    "with gd_graph.as_default():\n",
    "    X = tf.constant(X_train_biased, dtype=tf.float32, name=\"X\")\n",
    "    y = tf.constant(y_train.reshape(-1,1), dtype=tf.float32, name=\"y\")\n",
    "    # Initialize theta variables with uniform random values\n",
    "    theta = tf.Variable( tf.random_uniform([n, 1], -1.0, 1.0), name=\"theta\" )\n",
    "    # Compute the predictions and error\n",
    "    y_pred = tf.matmul( X, theta, name=\"predictions\" )\n",
    "    error = y_pred - y\n",
    "    # Call on TF's mse function\n",
    "    mse = tf.reduce_mean( tf.square(error), name=\"mse\" )\n",
    "    # Gradient calculations\n",
    "    dJdtheta = (2.0/m) * tf.matmul( tf.transpose(X), error )\n",
    "    # Training/learning op. assign() computes a new value and assigns it to a TF variable\n",
    "    train_op = tf.assign( theta, theta - alpha*dJdtheta )\n",
    "    \n",
    "    init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 MSE =  7.3624883\n",
      "Epoch  100 MSE =  0.81129843\n",
      "Epoch  200 MSE =  0.696744\n",
      "Epoch  300 MSE =  0.64358246\n",
      "Epoch  400 MSE =  0.6069529\n",
      "Epoch  500 MSE =  0.5814039\n",
      "Epoch  600 MSE =  0.5635774\n",
      "Epoch  700 MSE =  0.55113834\n",
      "Epoch  800 MSE =  0.5424594\n",
      "Epoch  900 MSE =  0.53640234\n",
      "Epoch  1000 MSE =  0.5321771\n",
      "Epoch  1100 MSE =  0.5292278\n",
      "Epoch  1200 MSE =  0.5271701\n",
      "Epoch  1300 MSE =  0.52573436\n",
      "Epoch  1400 MSE =  0.52473235\n",
      "Epoch  1500 MSE =  0.52403355\n",
      "Epoch  1600 MSE =  0.52354574\n",
      "Epoch  1700 MSE =  0.52320516\n",
      "Epoch  1800 MSE =  0.5229676\n",
      "Epoch  1900 MSE =  0.52280194\n",
      "[[ 2.0638661 ]\n",
      " [ 0.8138546 ]\n",
      " [ 0.11957388]\n",
      " [-0.2204336 ]\n",
      " [ 0.2469558 ]\n",
      " [-0.00463181]\n",
      " [-0.02959383]\n",
      " [-0.8791873 ]\n",
      " [-0.8504208 ]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session( graph=gd_graph ) as sess:\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    for i in range(n_epochs):\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(\"Epoch \", i, \"MSE = \", mse.eval())\n",
    "        sess.run(train_op)\n",
    "    \n",
    "    # At the end, print the current thetas\n",
    "    print(theta.eval())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are pretty good compared to the normal equation. But it would be nice to not have to compute the derivative by hand all the time, especially for more difficult functions, e.g. regularized cost functions. Next, I will use *autodiff* to automatically compute the gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dJdtheta/predictions_grad/MatMul_1:0\", shape=(9, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "gd_graph2 = tf.Graph()\n",
    "with gd_graph2.as_default():\n",
    "    X = tf.constant(X_train_biased, dtype=tf.float32, name=\"X\")\n",
    "    y = tf.constant(y_train.reshape(-1,1), dtype=tf.float32, name=\"y\")\n",
    "    # Initialize theta variables with uniform random values\n",
    "    theta = tf.Variable( tf.random_uniform([n, 1], -1.0, 1.0), name=\"theta\" )\n",
    "    # Compute the predictions and error\n",
    "    y_pred = tf.matmul( X, theta, name=\"predictions\" )\n",
    "    error = y_pred - y\n",
    "    # Call on TF's mse function\n",
    "    mse = tf.reduce_mean( tf.square(error), name=\"mse\" )\n",
    "    # Using tf's autodiff capability\n",
    "    dJdtheta = tf.gradients( mse, [theta], name=\"dJdtheta\" )[0]\n",
    "    print(dJdtheta)\n",
    "    \n",
    "    # Training/learning op. assign() computes a new value and assigns it to a TF variable\n",
    "    train_op = tf.assign( theta, theta - alpha*dJdtheta )\n",
    "    \n",
    "    init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 MSE =  7.447377\n",
      "Epoch  100 MSE =  0.6730163\n",
      "Epoch  200 MSE =  0.55053324\n",
      "Epoch  300 MSE =  0.54264486\n",
      "Epoch  400 MSE =  0.5386119\n",
      "Epoch  500 MSE =  0.5355076\n",
      "Epoch  600 MSE =  0.5330425\n",
      "Epoch  700 MSE =  0.5310713\n",
      "Epoch  800 MSE =  0.52948725\n",
      "Epoch  900 MSE =  0.52820766\n",
      "Epoch  1000 MSE =  0.5271705\n",
      "Epoch  1100 MSE =  0.526326\n",
      "Epoch  1200 MSE =  0.52563715\n",
      "Epoch  1300 MSE =  0.5250738\n",
      "Epoch  1400 MSE =  0.5246114\n",
      "Epoch  1500 MSE =  0.5242318\n",
      "Epoch  1600 MSE =  0.52391905\n",
      "Epoch  1700 MSE =  0.5236611\n",
      "Epoch  1800 MSE =  0.5234484\n",
      "Epoch  1900 MSE =  0.52327186\n",
      "[[ 2.0638661 ]\n",
      " [ 0.85329   ]\n",
      " [ 0.12174978]\n",
      " [-0.29710376]\n",
      " [ 0.31221607]\n",
      " [-0.00445192]\n",
      " [-0.02958686]\n",
      " [-0.8215701 ]\n",
      " [-0.7977139 ]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session( graph=gd_graph2 ) as sess:\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    for i in range(n_epochs):\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(\"Epoch \", i, \"MSE = \", mse.eval())\n",
    "        sess.run(train_op)\n",
    "    \n",
    "    # At the end, print the current thetas\n",
    "    print(theta.eval())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to roll all of the above into a simple call to a tf `Optimizer`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdwithopt_graph = tf.Graph()\n",
    "# All the same intialization code, but then call on a MomentumOptimizer (or whatever other flaver)\n",
    "with gdwithopt_graph.as_default():\n",
    "    X = tf.constant(X_train_biased, dtype=tf.float32, name=\"X\")\n",
    "    y = tf.constant(y_train.reshape(-1,1), dtype=tf.float32, name=\"y\")\n",
    "    # Initialize theta variables with uniform random values\n",
    "    theta = tf.Variable( tf.random_uniform([n, 1], -1.0, 1.0), name=\"theta\" )\n",
    "    # Compute the predictions and error\n",
    "    y_pred = tf.matmul( X, theta, name=\"predictions\" )\n",
    "    error = y_pred - y\n",
    "    # Call on TF's mse function\n",
    "    mse = tf.reduce_mean( tf.square(error), name=\"mse\" )\n",
    "    \n",
    "    # The optimizer:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=alpha)\n",
    "    training_op = optimizer.minimize(mse)\n",
    "    #optimizer = tf.train.MomentumOptimizer(learning_rate=alpha, momentum=0.9)\n",
    "    \n",
    "    init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 MSE =  8.766612\n",
      "Epoch  100 MSE =  0.68664193\n",
      "Epoch  200 MSE =  0.5629296\n",
      "Epoch  300 MSE =  0.55095947\n",
      "Epoch  400 MSE =  0.5436051\n",
      "Epoch  500 MSE =  0.5382778\n",
      "Epoch  600 MSE =  0.5343784\n",
      "Epoch  700 MSE =  0.5315074\n",
      "Epoch  800 MSE =  0.5293785\n",
      "Epoch  900 MSE =  0.527789\n",
      "Epoch  1000 MSE =  0.5265926\n",
      "Epoch  1100 MSE =  0.5256865\n",
      "Epoch  1200 MSE =  0.5249942\n",
      "Epoch  1300 MSE =  0.524461\n",
      "Epoch  1400 MSE =  0.5240476\n",
      "Epoch  1500 MSE =  0.52372515\n",
      "Epoch  1600 MSE =  0.52347136\n",
      "Epoch  1700 MSE =  0.52327\n",
      "Epoch  1800 MSE =  0.5231109\n",
      "Epoch  1900 MSE =  0.5229829\n",
      "[[ 2.0638661 ]\n",
      " [ 0.8442006 ]\n",
      " [ 0.12141337]\n",
      " [-0.27915266]\n",
      " [ 0.29681358]\n",
      " [-0.00443377]\n",
      " [-0.02960958]\n",
      " [-0.8336215 ]\n",
      " [-0.8086179 ]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=gdwithopt_graph) as sess:\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    for i in range(n_epochs):\n",
    "        if i % 100 == 0:\n",
    "            print(\"Epoch \", i, \"MSE = \", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    # At the end, print the current thetas\n",
    "    print(theta.eval())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
